{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "spark.conf.set('spark.sql.repl.eagerEval.maxNumRows',20)\n",
    "spark.conf.set('sparl.sql.repl.eagerEval.truncate',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "from pyspark.sql import Row\n",
    "from datetime import datetime, date\n",
    "df = spark.createDataFrame([\n",
    "    Row(a=1,b=2.,c='string1',d=date(2000,1,1),e=datetime(2000,1,1,12,0)),\n",
    "    Row(a=2,b=3.,c='string2',d=date(2000,2,1),e=datetime(2000,1,2,13,0)),\n",
    "    Row(a=3,b=5.,c='string3',d=date(2000,3,1),e=datetime(2000,1,3,14,0)),\n",
    "    Row(a=4,b=7.,c='string4',d=date(2000,4,1),e=datetime(2000,1,4,15,0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "df_explicit_schema  = spark.createDataFrame([\n",
    "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
    "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
    "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
    "], schema='a long, b double, c string, d date, e timestamp')\n",
    "df_explicit_schema.show()\n",
    "df_explicit_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "df_explicit_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#6\n",
    "# Display 2 rows & column values 25 characters\n",
    "df.show(2,truncate=25) \n",
    "\n",
    "#+-----+-------------------------+\n",
    "#|Seqno|                    Quote|\n",
    "#+-----+-------------------------+\n",
    "#|    1|Be the change that you...|\n",
    "#|    2|Everyone thinks of cha...|\n",
    "#+-----+-------------------------+\n",
    "#only showing top 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "# Display DataFrame rows & columns vertically\n",
    "df.show(n=3,truncate=25,vertical=True)\n",
    "\n",
    "#-RECORD 0--------------------------\n",
    "# Seqno | 1                         \n",
    "# Quote | Be the change that you... \n",
    "#-RECORD 1--------------------------\n",
    "# Seqno | 2                         \n",
    "# Quote | Everyone thinks of cha... \n",
    "#-RECORD 2--------------------------\n",
    "# Seqno | 3                         \n",
    "# Quote | The purpose of our liv... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "from pyspark.sql.types import StructType,StructField, IntegerType, StringType\n",
    "\n",
    "data = [(1,23,4,5,5,3,533),(1,3,4,45,5,3,333),(1,3,4,5,5,3,333),(14,3,4,5,5,3,533),(1,3,4,5,5,33,3)]\n",
    "\n",
    "columns = StructType([StructField(\"id\",IntegerType(),True),\n",
    "                     StructField(\"number\",IntegerType(),True),\n",
    "                     StructField('number3',IntegerType(),True),\n",
    "                     StructField('number4',IntegerType(),True),\n",
    "                     StructField('number5',IntegerType(),True),\n",
    "                     StructField('number6',IntegerType(),True),\n",
    "                     StructField('number7',IntegerType(),True)])\n",
    "\n",
    "df = spark.createDataFrame(data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "from pyspark.sql import Row\n",
    "row=Row(\"James\",40)\n",
    "print(row[0] +\",\"+str(row[1]))\n",
    "\n",
    "\n",
    "row=Row(name=\"Alice\", age=11)\n",
    "print(row.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "\n",
    "Person = Row(\"name\", \"age\")\n",
    "p1=Person(\"James\", 40)\n",
    "p2=Person(\"Alice\", 35)\n",
    "print(p1.name +\",\"+p2.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "windowSpec  = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
    "df.withColumn(\"row_number\",row_number().over(windowSpec)) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "from pyspark.sql.functions import rank\n",
    "windowSpec  = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
    "df.withColumn(\"rank\",rank().over(windowSpec)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
