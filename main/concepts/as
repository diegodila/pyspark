1.1 what's difference between repartion and coalesce in spark?


1.2 why are spark repartion and coalesce expensive?


1.3 what's function of spark coalesce?


2.1 o que é um cluster?


2.2 arquitetura parecida com um cluster mas não são?


2.3 quais sao os metodos de tolerancia a falha do spark?


2.4 como o spark ajuda no processamento?


2.5 objetivo principal do spark?


2.6 spark é um projeto ativo?


como surgiu o hadoop?
pelo gfs, do google file system

hive foi criado por qual empresa?
facebook

hive utilizada qual linguagem sobre o hdfs?
sql

-------------------------------------------------------------------------------------------------------
o que é o spark?
é um projeto de codigo aberto para processar dados

quais são as principais caracteristicas do spark?
replicação
cluterização
alta disponibilidade
processamento de dados em memoria

o que é hdfs?
é um sistema de arquivos distribuido

o que é cluster?
são maquinas que operam com o mesmo objetivo

como funciona a replicação e tolerancia a falha no spark?
os dados são copiados em nós do cluster

qual o custo que tem de processar dados?
computacional

qual linguagem utilizada no spark?
scala 

--------------------------------------------------------

quais os principais componentes do spark?
spark machine learning mlib
spark sql
spark grafos

o que o sparksql permite?
leitura de dados tabulares usando a sintaxe sql

spark streaming quais suas caracteristicas?
leitura de dados tabulares e escrita no final da tabela

como o spark funciona?

o que é uma grafo?

o que é aciclicos dirigidos?
aciclicos nao tem ciclos 
dirigidos tem um direção

o que é tungsten?
é o motor de execução do spark, com foco em eficiencia da cpu

qual é a estrutura do spark?
driver, manager, executer

o que o driver faz?


o que o manager faz?


quais managers são possiveis de utilizar com o spark?


o que o executer faz?


cite 2 elementos do spark?



dentro de transformaçoes e ações, qual o comportamento do dataframe?


quando uma tranformação ocorre no dataframe o que ocorre?


qual a vantagem do dado ser imutável?


quando ocorre o processamento de transformação de fato no spark?


quando processamos dados no spark quais os 2 tipos de operações que fazemos?


o que lazy evaluation no spark?



quais os 2 tipos que podem ser uma transformação?


o que é narrow?


o que é wide?


como os dados do spark são processados (componentes)?


--------------------------------------------------------

o que é SparkContext?


o que é SparkSession?

---------------------------------------------------------

como eram armazenados os dados antigamente?


quais são os principais formatos de arquivos abertos para big data?


quais são caracteristicas dos armazem de dados em big data atualmente?



o que é formato de dado parquet?


o que é formato de dado arvro?


o que é formato de dado orc?


qual a melhor perfomance para escrita do dado linha ou coluna?


como os banco de dados relacionais são otimizados em perfomance?


em geral qual é melhor na criação e compressão, parquet ou orc?


em geral qual é melhor na performance, parquet ou orc?


qual é formato de arquivos padrão do spark?










