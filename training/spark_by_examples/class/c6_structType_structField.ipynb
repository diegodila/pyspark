{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. StructType – Defines the structure of the Dataframe\n",
    "    PySpark provides from pyspark.sql.types import StructType class to define the structure of the DataFrame.\n",
    "\n",
    "    StructType is a collection or list of StructField objects.\n",
    "\n",
    "    PySpark printSchema() method on the DataFrame shows StructType columns as struct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. StructField – Defines the metadata of the DataFrame column\n",
    "\n",
    "    PySpark provides pyspark.sql.types import StructField class to define the columns which include column name(String), column type (DataType), nullable column (Boolean) and metadata (MetaData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Using PySpark StructType & StructField with DataFrame\n",
    "\n",
    "    While creating a PySpark DataFrame we can specify the structure using StructType and StructField classes. As specified in the introduction, StructType is a collection of StructField’s which is used to define the column name, data type, and a flag for nullable or not. Using StructField we can also add nested struct schema, ArrayType for arrays, and MapType for key-value pairs which we will discuss in detail in later sections.\n",
    "\n",
    "    The below example demonstrates a very simple example of how to create a StructType & StructField on DataFrame and it’s usage with sample data to support it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    " \n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "\n",
    "data = [(1,23,4,5,5,3,533),(1,3,4,45,5,3,333),(1,3,4,5,5,3,333),(14,3,4,5,5,3,533),(1,3,4,5,5,33,3)]\n",
    "\n",
    "columns = StructType([StructField(\"id\",IntegerType(),True),\n",
    "                     StructField(\"number\",IntegerType(),True),\n",
    "                     StructField('number3',IntegerType(),True),\n",
    "                     StructField('number4',IntegerType(),True),\n",
    "                     StructField('number5',IntegerType(),True),\n",
    "                     StructField('number6',IntegerType(),True),\n",
    "                     StructField('number7',IntegerType(),True)])\n",
    "\n",
    "df = spark.createDataFrame(data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------+-------+-------+-------+\n",
      "| id|number|number3|number4|number5|number6|number7|\n",
      "+---+------+-------+-------+-------+-------+-------+\n",
      "|  1|    23|      4|      5|      5|      3|    533|\n",
      "|  1|     3|      4|     45|      5|      3|    333|\n",
      "|  1|     3|      4|      5|      5|      3|    333|\n",
      "| 14|     3|      4|      5|      5|      3|    533|\n",
      "|  1|     3|      4|      5|      5|     33|      3|\n",
      "+---+------+-------+-------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
