1.1 what's difference between repartion and coalesce in spark?
repartition() is used to increase or decrease the RDD/DataFrame partitions whereas the PySpark coalesce() is used to only decrease the number of partitions in an efficient way

1.2 why are spark repartion and coalesce expensive?
because they are very expensive operations as they shuffle the data across many partitions hence try to minimize using these as much as possible.

1.3 what's function of spark coalesce?
becase it's used only to reduce the number of partitions. This is an optimized or improved version of repartition() where the movement of the data across the partitions is lower using coalesce.

o que é um cluster?
são maquinas operando com o mesmo objetivo

arquitetura parecida com um cluster mas não são?
rede de computadores

quais sao os metodos de tolerancia a falha do spark?
replicação, copiam os dados em nós do cluster

como o spark ajuda no processamento?
particionando os dados e distribuindo o processamento entre os nos do cluster

objetivo principal do spark?
processamento massivo de dados


spark é um projeto ativo?
sim

como surgiu o hadoop?
pelo gfs, do google file system

hive foi criado por qual empresa?
facebook

hive utilizada qual linguagem sobre o hdfs?
sql

-------------------------------------------------------------------------------------------------------
o que é o spark?
é um projeto de codigo aberto para processar dados

quais são as principais caracteristicas do spark?
replicação
cluterização
alta disponibilidade
processamento de dados em memoria

o que é hdfs?
é um sistema de arquivos distribuido

o que é cluster?
são maquinas que operam com o mesmo objetivo


como funciona a replicação e tolerancia a falha no spark?
os dados são copiados em nós do cluster


qual o custo que tem de processar dados?
computacional

qual a origem da linguagem do spark?
scala 

--------------------------------------------------------

quais os principais componentes do spark?
spark machine learnign mlib
spark sql
spark grafos

o que o sparksql permite?
leitura de dados tabulares usando a sintaxe sql

spark streming quais suas caracteristicas?
leitura de dados tabulares e escrita no final da tabela

como o spark funciona?


o que é uma grafo?


o que é aciclicos dirigidos?
aciclicos nao tem ciclos 
dirigidos tem um direção

o que é tungsten?
é o motor de execução do spark, com foco em eficiencia da cpu

qual é a estrutura do spark?
driver, manager, executer

o que o driver faz?


o que o manager faz?


quais managers são possiveis de utilizar com o spark?


o que o executer faz?


cite 2 elementos do spark?



dentro de transformaçoes e ações, qual o comportamento do dataframe?


quando uma tranformação ocorre no dataframe o que ocorre?


qual a vantagem do dado ser imutável?


quando ocorre o processamento de transformação de fato no spark?


quando processamos dados no spark quais os 2 tipos de operações que fazemos?


o que lazy evaluation no spark?



quais os 2 tipos que podem ser uma transformação?


o que é narrow?


o que é wide?


como os dados do spark são processados (componentes)?


--------------------------------------------------------

o que é SparkContext?


o que é SparkSession?

---------------------------------------------------------

como eram armazenados os dados antigamente?


quais são os principais formatos de arquivos abertos para big data?


quais são caracteristicas dos armazem de dados em big data atualmente?



o que é formato de dado parquet?


o que é formato de dado arvro?


o que é formato de dado orc?


qual a melhor perfomance para escrita do dado linha ou coluna?


como os banco de dados relacionais são otimizados em perfomance?


em geral qual é melhor na criação e compressão, parquet ou orc?


em geral qual é melhor na performance, parquet ou orc?


qual é formato de arquivos padrão do spark?










